Ä°Ã§eriÄŸe geÃ§
Åunu dedin:
merhaba ÅŸÃ¶yle bir planÄ±m var:
1- external source stream data gelecek bunlar .ts formatÄ±nda iÃ§inde metadata var.
2- bir servis ile bu metadata ve videoyu ayÄ±rÄ±yorum.
3- bu ayrÄ±lan video ve metadayÄ± antmedia source olarak veriyorum.
4- yine metadatayÄ± UI da haritada kullanmak iÃ§in gÃ¶nderiyor olacaÄŸÄ±m.

buradaki mimari de 
data service -> adaptor-> dinleyeceÄŸi data, url, port vs bilgisini verecek.
sonra adaptor yayÄ±nÄ± alÄ±p iÅŸleyecek ÅŸu ÅŸekilde:

external source-> adaptor -> antmedia -> UI video 
ve
external source-> adaptor -> antmedia -> UI background -> Map
gelecek ÅŸekilde.

burada ÅŸuna karar vermek lazÄ±m:
ui background bu datalarÄ± nasÄ±l aktarabilirim? bu websocket ise nasÄ±l iki tarafta birden socket tanÄ±mlayacaÄŸÄ±m?
burada tetikleme nasÄ±l olmalÄ±?
bana best practisie olarak Ã§izebilir misin?
ChatGPT:
Tamam, gayet net bir problem tanÄ±mÄ± yapmÄ±ÅŸsÄ±n ğŸ‘
Ben bunu gerÃ§ek hayatta sorunsuz Ã§alÄ±ÅŸan bir mimari Ã¼zerinden anlatayÄ±m, artÄ± neden o ÅŸekilde daha doÄŸru olduÄŸuna da deÄŸineyim.

Ã–nce resmi netleÅŸtirelim (akÄ±ÅŸ)
Senin anlattÄ±ÄŸÄ±n haliyle iki ayrÄ± ama senkron akan veri var:

Video stream (yÃ¼ksek bant, real-time)

Metadata (dÃ¼ÅŸÃ¼k bant, event / konum / zaman bilgisi)

BunlarÄ±n aynÄ± kaynaktan Ã§Ä±kmasÄ± ama UIâ€™da farklÄ± ÅŸekillerde tÃ¼ketilmesi Ã§ok doÄŸru bir ayrÄ±m.

Temel prensip (Best Practice)
Video = media pipeline
Metadata = event/data pipeline

Yani:

Videoyu asla WebSocket ile taÅŸÄ±maya Ã§alÄ±ÅŸma

Metadataâ€™yÄ± asla video streamâ€™in iÃ§ine tekrar gÃ¶mme

Bunlar ayrÄ± yollar olmalÄ± ama aynÄ± time-referenceâ€™a baÄŸlÄ± olmalÄ±.

Ã–nerilen mimari (high level)
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ External Source   â”‚
              â”‚ (.ts + metadata)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚     Adaptor      â”‚
               â”‚  (Demux + Parse) â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                               â”‚
        â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ant Media      â”‚        â”‚   Metadata Service  â”‚
â”‚  (RTMP / WebRTC) â”‚        â”‚ (WS / PubSub / API) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                               â”‚
        â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI Video Player  â”‚        â”‚ UI Background (Map) â”‚
â”‚ (Ant SDK)        â”‚        â”‚ (WS Subscriber)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Kritik karar noktalarÄ± (asÄ±l sorduÄŸun yerler)
1ï¸âƒ£ UI background metadataâ€™yÄ± nasÄ±l almalÄ±?
Cevap:
ğŸ‘‰ WebSocket (ya da SSE)
Ama doÄŸrudan adaptorâ€™dan deÄŸil.

Neden?

UI sayÄ±sÄ± artar

Backpressure olur

Adaptor stateful olur (kÃ¶tÃ¼)

DoÄŸru yol:
Adaptor â†’ Metadata Service â†’ UIâ€™lar
Metadata Service:

Stateless

Scale edilebilir

Gerekirse cacheâ€™li

Gerekirse replay yapabilir

2ï¸âƒ£ â€œWebSocket ise iki tarafta socketâ€™i nasÄ±l tanÄ±mlarÄ±m?â€
Bu Ã§ok Ã¶nemli bir soru ve cevabÄ± net:

âŒ Adaptor â†’ UI direkt socket aÃ§maz
âœ… Adaptor â†’ Metadata Service publish eder

Ã–rnek:
Adaptor:

WS client ya da

Kafka / Redis / NATS publish ya da

HTTP POST (low freq ise)

Metadata Service:

WebSocket server

UIâ€™lar buraya baÄŸlanÄ±r

Adaptor
  â””â”€â”€ publish(metadata)

Metadata Service
  â”œâ”€â”€ WS /metadata?streamId=123
  â”œâ”€â”€ WS /metadata?streamId=456
UI:

ws://metadata-service/metadata?streamId=123
3ï¸âƒ£ Tetikleme nasÄ±l olmalÄ±?
Tek tetikleyici: external source stream

Adaptorâ€™un sorumluluÄŸu:

.ts iÃ§inden:

video â†’ Ant Media

metadata â†’ publish

UI bir ÅŸey tetiklemez.
UI sadece subscriber.

Bu seni ÅŸunlardan kurtarÄ±r:

race condition

UI refresh problemi

reconnect karmaÅŸasÄ±

Zaman senkronu (Ã§ok kritik)
Metadata ile videonun aynÄ± frame/timeâ€™a denk gelmesi gerekiyor.

Best practice:

Metadata iÃ§ine PTS / timestamp koy

UIâ€™da:

video currentTime

metadata timestamp karÅŸÄ±laÅŸtÄ±r

Ã–rnek metadata:

{
  "streamId": "cam-12",
  "timestamp": 1700001234.233,
  "lat": 41.012,
  "lon": 28.978,
  "speed": 32
}
Teknoloji Ã¶nerileri (pratik)
Adaptor
FFmpeg / GStreamer

TS demux

Metadata parser

RTMP â†’ Ant Media

Metadata Service
Node.js / Go

WebSocket

Redis Pub/Sub (opsiyonel)

UI
Ant Media JS SDK

Native WebSocket

Map: Leaflet / Mapbox / Google Maps

Ã–zetle â€œbest practiceâ€ kararlar
âœ” Video ve metadata ayrÄ± pipeline
âœ” UI â†’ adaptor baÄŸlanmaz
âœ” Metadata iÃ§in central WS service
âœ” Adaptor sadece producer
âœ” UI sadece consumer
âœ” Timestamp ile senkronizasyon

Ä°stersen bir sonraki adÄ±mda:

Sequence diagram Ã§izebilirim

Adaptor pseudo-code

WebSocket message contract

ya da â€œbunu Kafka ile mi WS ile mi yapayÄ±m?â€ tartÄ±ÅŸmasÄ±na girebiliriz

Hangisinden devam edelim? ğŸ‘€

Åunu dedin:
sonraki adÄ±mdan Ã¶nce, ben gÃ¶rÃ¼ntÃ¼ ve metadatayÄ± antmedia Ã¼zerinden doÄŸrudan player aktaracaÄŸÄ±m ve burada senkron sorunu yaÅŸamam diye dÃ¼ÅŸÃ¼nÃ¼yorum ama sen Metadataâ€™yÄ± asla video streamâ€™in iÃ§ine tekrar gÃ¶mme diyorsun. oysaki ben antmedia ile kaydetmem lazÄ±m metadatasÄ±yla
ChatGPT:
Ã‡ok gÃ¼zel noktaya bastÄ±n â€” burada gerÃ§ekten iki farklÄ± â€œdoÄŸruâ€ var ve senin use-caseâ€™in ikisinin ortasÄ±nda duruyor. O yÃ¼zden netleÅŸtireyim, Ã¶nceki cÃ¼mlem biraz genel kural gibiydi; kayÄ±t gereksinimi devreye girince tablo deÄŸiÅŸiyor.

Åunu baÅŸtan sÃ¶yleyeyim:
ğŸ‘‰ Ant Media Ã¼zerinden video + metadata birlikte akabilir ve kaydedilebilir
ğŸ‘‰ Ama bu metadataâ€™nÄ±n UIâ€™da harita / background logic iÃ§in tÃ¼ketilme ÅŸekli yine ayrÄ± olmalÄ±

Yani â€œaslaâ€ dememin istisnasÄ± recording & playback senaryosu ğŸ‘

Senin senaryonu doÄŸru ÅŸekilde ayÄ±ralÄ±m
Senin aslÄ±nda 3 ayrÄ± ihtiyaÃ§ var:

Live playback (UI player)

Live metadata consumption (map, telemetry)

Recorded playback (video + metadata senkron)

BunlarÄ±n hepsi aynÄ± pipelineâ€™da olursa kÄ±sa vadede kolay, uzun vadede Ã§ok acÄ±tÄ±r.

Ant Media metadataâ€™yÄ± ne iÃ§in kullanmalÄ±?
âœ” DOÄRU KULLANIM
KayÄ±t almak

Playback sÄ±rasÄ±nda frame-accurate senkron

âŒ YANLIÅ KULLANIM
UI business logic

Map update

Filtering / replay / aggregation

En saÄŸlÄ±klÄ± hibrit mimari (senin ihtiyacÄ±na birebir)
External Source (.ts + metadata)
        â”‚
        â–¼
      Adaptor
        â”‚
        â”œâ”€â”€ Video + Embedded Metadata â”€â”€â–¶ Ant Media â”€â”€â–¶ UI Player
        â”‚                                   â”‚
        â”‚                                   â””â”€â”€ Recording (OK)
        â”‚
        â””â”€â”€ Parsed Metadata â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Metadata Service â”€â–¶ UI Map
ğŸ‘‰ AynÄ± metadata iki kez kullanÄ±lÄ±yor ama farklÄ± amaÃ§larla

â€œBen senkron sorunu yaÅŸamamâ€ dÃ¼ÅŸÃ¼ncen neden doÄŸru?
HaklÄ±sÄ±n Ã§Ã¼nkÃ¼:

Metadata aynÄ± TS stream iÃ§inden geliyor

Ant Media frame timeâ€™Ä±na baÄŸlÄ± kalÄ±yor

KayÄ±t sÄ±rasÄ±nda drift olmaz

Playback iÃ§in bu mÃ¼kemmel.

Ama ğŸ‘‡

Neden UI iÃ§in yine ayÄ±rmak zorundasÄ±n?
1ï¸âƒ£ Player metadata eriÅŸimi sÄ±nÄ±rlÄ±
Ant Media:

SEI

ID3

custom data

Bunlar:

Player SDKâ€™ya her zaman expose edilmez

TarayÄ±cÄ±ya dÃ¼zgÃ¼n dÃ¼ÅŸmez

Map logic iÃ§in ergonomik deÄŸildir

2ï¸âƒ£ UI timing kontrolÃ¼ zayÄ±f
Map:

â€œVideo pausedâ€

â€œSeek yapÄ±ldÄ±â€

â€œPlayback speed x2â€

BunlarÄ±n hepsinde:

metadataâ€™yÄ± yeniden hesaplaman gerekir

player eventâ€™leriyle senkronlamak zorlaÅŸÄ±r

3ï¸âƒ£ Recording replay senaryosu
KayÄ±ttan izlerken:

â€œÅŸu an hangi noktadayÄ±m?â€

â€œÅŸu frameâ€™de konum neydi?â€

Bunu:

sadece video iÃ§indeki metadata ile yapmak iÅŸkence

APIâ€™den timestamp â†’ metadata Ã§ekmek cennet

Ant Media tarafÄ±nda metadata nasÄ±l gÃ¶mÃ¼lmeli?
Best practice:

Recording iÃ§in:

ID3 (HLS)

SEI (WebRTC / RTMP)

Live UI iÃ§in:

ignore edilebilir

Adaptor:

TS demux
 â”œâ”€â”€ video â†’ Ant Media
 â””â”€â”€ metadata
      â”œâ”€â”€ embed (for record)
      â””â”€â”€ publish (for UI)
â€œO zaman iki kere gÃ¶ndermiÅŸ olmuyor muyum?â€
Evet.
Ve bu bilinÃ§li yapÄ±lan doÄŸru bir tekrar.

Metadata:

kÃ¼Ã§Ã¼k

ucuz

ama farklÄ± lifecycleâ€™lara sahip

Karar aÄŸacÄ± (Ã§ok net)
Soru	Ant Media iÃ§i	Metadata Service
Live video	âœ…	âŒ
Recording	âœ…	âŒ
Playback sync	âœ…	âŒ
Map / UI logic	âŒ	âœ…
Replay / seek	âŒ	âœ…
Filtering	âŒ	âœ…
Scale	âŒ	âœ…
Bottom line
Ant Media = â€œmedya gerÃ§eÄŸiâ€
Metadata Service = â€œuygulama gerÃ§eÄŸiâ€

Sen:

Ant Mediaâ€™ya metadataâ€™yÄ± gÃ¶m

UIâ€™ya metadataâ€™yÄ± ayrÄ± servisle ver

Bu mimari:

Senkronu bozmuyor

Recordingâ€™i garanti ediyor

UIâ€™yÄ± temiz tutuyor

YarÄ±n analytics eklersen aÄŸlatmÄ±yor ğŸ˜„

Ä°stersen bir sonraki adÄ±mda:

Ant Media + ID3 / SEI Ã¶rnek akÄ±ÅŸ

Recording replayâ€™de metadata API tasarÄ±mÄ±

Player event â†” metadata sync algoritmasÄ±

Hangisiyle devam edelim?

Åunu dedin:
son haliyle Ã¶nce yapÄ±yÄ± tekrar Ã§izelim. sonra Ä°stersen bir sonraki adÄ±mda:

Ant Media + ID3 / SEI Ã¶rnek akÄ±ÅŸ

Recording replayâ€™de metadata API tasarÄ±mÄ±

Player event â†” metadata sync algoritmasÄ± bakalÄ±m
ChatGPT:
SÃ¼per, o zaman temiz ve â€œproduction-readyâ€ son haliyle ilerleyelim.
Ã–nce nihai mimariyi Ã§iziyorum, sonra dediÄŸin Ã¼Ã§ baÅŸlÄ±ÄŸÄ± net ve uygulanabilir ÅŸekilde aÃ§Ä±yorum.

1ï¸âƒ£ Nihai Mimari (final Ã§izim)
High-level (tek bakÄ±ÅŸta)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     External Source     â”‚
â”‚   (.ts + embedded meta) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Adaptor          â”‚
â”‚  TS Demux + Meta Parse  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                 â”‚
   â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ant Media   â”‚  â”‚  Metadata Service   â”‚
â”‚              â”‚  â”‚                     â”‚
â”‚  Video +     â”‚  â”‚  WS / REST / Cache  â”‚
â”‚  ID3 / SEI   â”‚  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UI Player    â”‚   â”‚ UI Background (Map) â”‚
â”‚ (Live/Replay)â”‚   â”‚  WS Subscriber      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
SorumluluklarÄ±n kesin ayrÄ±mÄ±
BileÅŸen	Sorumluluk
Adaptor	TS demux, metadata parse, embed + publish
Ant Media	Live stream, recording, playback
Metadata Service	UI metadata, replay, query
UI Player	Video playback
UI Background	Map, telemetry, business logic
2ï¸âƒ£ Ant Media + ID3 / SEI Ã¶rnek akÄ±ÅŸ
Ne zaman hangisi?
Protokol	Metadata
HLS	ID3
RTMP	onMetaData / SEI
WebRTC	SEI / DataChannel (opsiyonel)
Adaptor tarafÄ± (mantÄ±k)
TS packet
 â”œâ”€â”€ Video PES â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Ant Media
 â””â”€â”€ Metadata PES
      â”œâ”€â”€ embed â†’ ID3 / SEI (recording iÃ§in)
      â””â”€â”€ publish â†’ Metadata Service
ID3 metadata Ã¶rneÄŸi (HLS)
{
  "streamId": "cam-12",
  "pts": 902334.44,
  "lat": 41.012345,
  "lon": 28.978456,
  "alt": 120,
  "heading": 183
}
pts â†’ frame-accurate sync

Ant Media bunu segment iÃ§ine yazar

Recording sÄ±rasÄ±nda korunur âœ…

Ant Media playback tarafÄ±
Live:

Video akar

Metadata player seviyesinde opsiyonel

Replay:

Metadata segment iÃ§inde

Ama UI iÃ§in parse etmek zor

Bu yÃ¼zden ğŸ‘‡

3ï¸âƒ£ Recording replay iÃ§in Metadata API tasarÄ±mÄ±
Metadata Service API
1ï¸âƒ£ Zaman bazlÄ± sorgu (en kritik)
GET /streams/{streamId}/metadata?from=1700001000&to=1700001060
Response:

[
  {
    "ts": 1700001001.233,
    "lat": 41.01,
    "lon": 28.97
  },
  {
    "ts": 1700001002.433,
    "lat": 41.011,
    "lon": 28.971
  }
]
2ï¸âƒ£ Frame yakÄ±nlÄ±ÄŸÄ± (seek sonrasÄ±)
GET /streams/{streamId}/metadata/nearest?ts=1700001034.55
{
  "ts": 1700001034.53,
  "lat": 41.02,
  "lon": 28.99
}
3ï¸âƒ£ Live stream (WS)
ws://metadata-service/ws?streamId=cam-12
{
  "type": "live",
  "ts": 1700001055.12,
  "lat": 41.03,
  "lon": 28.98
}
Storage (Ã¶neri)
Live: Redis / in-memory

Record: Timeseries DB (Timescale / Influx / ClickHouse)

4ï¸âƒ£ Player event â†” metadata sync algoritmasÄ±
Live playback
Video time â†’ now()
Metadata â†’ push
Map â†’ last known state
Basit.

Replay (asÄ±l zor kÄ±sÄ±m)
Event akÄ±ÅŸÄ±
Player SEEK
   â†“
Player currentTime (seconds)
   â†“
Video start timestamp + currentTime
   â†“
Metadata API â†’ nearest(ts)
   â†“
Map update
Pseudo-code (UI tarafÄ±)
player.on("timeupdate", () => {
  const videoTs = videoStartTs + player.currentTime;

  const meta = metadataBuffer.findClosest(videoTs);
  if (meta) {
    map.update(meta.lat, meta.lon);
  }
});

player.on("seeked", async () => {
  const ts = videoStartTs + player.currentTime;
  const meta = await fetchNearest(ts);
  map.update(meta.lat, meta.lon);
});
Playback speed (x2, x4)
Video hÄ±zlanÄ±r

timeupdate daha sÄ±k gelir

Metadata buffer ahead of time preload edilir

5ï¸âƒ£ Neden bu yapÄ± â€œfinalâ€dir?
âœ” Recording metadata kaybolmaz
âœ” Live ve replay senkron
âœ” UI logic medyadan kopuk
âœ” Scale edilebilir
âœ” Debug edilebilir
âœ” YarÄ±n â€œanalyticsâ€, â€œAIâ€, â€œalertâ€ eklenir

Son sÃ¶z
Bu mimari:

Broadcast dÃ¼nyasÄ±nda

Telemetry + video iÅŸlerinde

Drone / vehicle / CCTV projelerinde

gerÃ§ekten kullanÄ±lan, kanÄ±tlanmÄ±ÅŸ bir yapÄ±.

Ä°stersen bir sonraki adÄ±mda:

Adaptor iÃ§in FFmpeg / GStreamer pipeline

Ant Media Ã¶zel config

Metadata Service iÃ§in schema + retention

Hangisine dalÄ±yoruz? ğŸš€

Åunu dedin:
sÄ±rasÄ±yla hepsine
ChatGPT:
Harika ğŸ˜„ o zaman uÃ§tan uca, gerÃ§ekten implement edilebilir ÅŸekilde sÄ±rasÄ±yla hepsine giriyorum.
Bunu â€œteoride gÃ¼zelâ€ deÄŸil, yarÄ±n kod yazarken referans alabileceÄŸin seviyede anlatacaÄŸÄ±m.

AÅŸamalar:

1ï¸âƒ£ Adaptor: FFmpeg / GStreamer pipeline
2ï¸âƒ£ Ant Media: ingest + recording config
3ï¸âƒ£ Metadata Service: schema + retention + realtime

1ï¸âƒ£ Adaptor â€“ TS demux + dual output pipeline
Adaptorâ€™un tek gÃ¶revi var:

â€œExternal sourceâ€™tan gelen TSâ€™i parÃ§ala,
videoyu Ant Mediaâ€™ya gÃ¶nder,
metadataâ€™yÄ± ikiye bÃ¶l: embed + publishâ€

1.1 Adaptor iÃ§ mimarisi
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TS Listener   â”‚  (UDP / TCP / HTTP)
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TS Demux       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
 â”‚              â”‚
 â–¼              â–¼
Video PES    Metadata PES
 â”‚              â”‚
 â–¼              â–¼
Ant Media     Parser
 (RTMP)        â”‚
               â”œâ”€â”€ embed (ID3 / SEI)
               â””â”€â”€ publish (Metadata Service)
1.2 FFmpeg tabanlÄ± yaklaÅŸÄ±m (en pratik)
TS â†’ RTMP (video + embedded metadata)
ffmpeg \
  -i input.ts \
  -map 0:v \
  -c:v copy \
  -f flv \
  rtmp://antmedia/live/streamId
Metadata iÃ§in iki yol var:

Yol A (HLS / ID3 â€“ Ã¶nerilen)
Metadataâ€™yÄ± ID3 timed metadata olarak ekle

Ant Media HLS segmentlerine yazar

ffmpeg \
  -i input.ts \
  -map 0:v \
  -map 0:d \
  -c copy \
  -f hls \
  -hls_flags program_date_time \
  output.m3u8
Burada 0:d = data stream (metadata)

Yol B (SEI â€“ RTMP / WebRTC)
Metadataâ€™yÄ± H.264 SEI iÃ§ine koy

Frame-accurate ama parse zor

Genelde:

recording iÃ§in OK

UI iÃ§in NO

1.3 Metadata publish (Adaptor â†’ Metadata Service)
Adaptor metadataâ€™yÄ± parse eder etmez:

{
  "streamId": "cam-12",
  "pts": 902334.44,
  "ts": 1700001234.233,
  "lat": 41.012,
  "lon": 28.978,
  "speed": 32
}
Bunu:

Redis Pub/Sub

Kafka

ya da direkt WS client

ile Metadata Serviceâ€™e yollar.

ğŸ‘‰ Adaptor ASLA UI ile konuÅŸmaz

2ï¸âƒ£ Ant Media â€“ ingest, recording, playback
2.1 Stream ingest
RTMP ingest (en stabil)

rtmp://antmedia/live/{streamId}
Ant Media:

Live yayÄ±n

HLS Ã¼retir

Recording alÄ±r

2.2 Recording ayarlarÄ±
Ant Media panel / config:

mp4MuxingEnabled=true
hlsMuxingEnabled=true
addDateTimeToHLS=true
Bu sayede:

Segmentâ€™ler timestamp taÅŸÄ±r

ID3 metadata korunur

2.3 Playback senaryosu
Live
UI player â†’ Ant Media

Metadata ayrÄ± servisten

Replay
UI player â†’ Ant Media (vod)

UI background â†’ Metadata Service (time-based)

Bu ayrÄ±m Ã§ok Ã¶nemli.

3ï¸âƒ£ Metadata Service â€“ schema, retention, realtime
Burada iÅŸin â€œuygulama beyniâ€ var.

3.1 Veri modeli (minimum ama yeterli)
Table: stream_metadata
stream_id   TEXT
ts          TIMESTAMP
pts         DOUBLE PRECISION
lat         DOUBLE PRECISION
lon         DOUBLE PRECISION
alt         DOUBLE PRECISION
speed       DOUBLE PRECISION
heading     DOUBLE PRECISION
Index:

(stream_id, ts)
3.2 Retention strategy
Live buffer
Redis

Son 30â€“60 saniye

Recorded
TimescaleDB / ClickHouse

7 gÃ¼n / 30 gÃ¼n / policyâ€™ye gÃ¶re

3.3 API contract
Live WebSocket
ws://metadata/ws?streamId=cam-12
{
  "type": "live",
  "ts": 1700001055.12,
  "lat": 41.03,
  "lon": 28.98
}
Time range (replay)
GET /streams/cam-12/metadata?from=1700001000&to=1700001060
Nearest (seek sonrasÄ±)
GET /streams/cam-12/metadata/nearest?ts=1700001034.55
3.4 UI sync algoritmasÄ± (son kez net)
Replay sync flow
Player currentTime
   â†“
videoStartTs + currentTime
   â†“
Metadata Service
   â†“
Map update
UI pseudo-code
player.on("timeupdate", () => {
  const ts = videoStartTs + player.currentTime;
  const meta = buffer.closest(ts);
  if (meta) map.update(meta);
});

player.on("seeked", async () => {
  const ts = videoStartTs + player.currentTime;
  const meta = await api.nearest(ts);
  map.update(meta);
});
4ï¸âƒ£ Bu yapÄ±nÄ±n sana kazandÄ±rdÄ±klarÄ±
âœ” Frame-accurate recording
âœ” Live & replay senkron
âœ” UI baÄŸÄ±msÄ±z
âœ” Scale edilebilir
âœ” Debug edilebilir
âœ” YarÄ±n AI / alert / analytics eklenir

GerÃ§ekÃ§i son yorum
Bu mimari:

Drone

AraÃ§ telemetrisi

CCTV + GIS

Military / defense projelerinde

aynen bu ÅŸekilde kuruluyor.

Ä°stersen bir sonraki turda:

GStreamer pipeline (daha advanced)

Ant Media SDK tarafÄ±nda metadata hookâ€™larÄ±

Metadata Serviceâ€™i Kafka mÄ± Redis mi? diye tartÄ±ÅŸalÄ±m

Buradan nereye dalalÄ±m? ğŸš€

Åunu dedin:
1.2 FFmpeg tabanlÄ± yaklaÅŸÄ±m (en pratik) hem gÃ¶rÃ¼ntÃ¼, hem de metadatayÄ± mÄ± gÃ¶nderiyorum antmedia ya. yoksa yolA ve yolB de belirtilenler mi yapÄ±lmalÄ±?  YolB biraz daha geniÅŸletir misin? yol A daki kod tek baÅŸÄ±na yeterli mi? ancak bende ts deÄŸil stream ÅŸeklinde gelecek drone gibi dÃ¼ÅŸÃ¼n
ChatGPT:
Ã‡ok yerinde sorular â€” burada kafa karÄ±ÅŸmasÄ± %100 normal, Ã§Ã¼nkÃ¼ FFmpeg Ã¶rnekleri genelde bu ayrÄ±mÄ± net anlatmaz. Åimdi bunu net Ã§izgilerle ayÄ±ralÄ±m.

KÄ±sa ama kesin cevap:
ğŸ‘‰ Ant Mediaâ€™ya her zaman video gÃ¶nderiyorsun
ğŸ‘‰ Metadata iÃ§in AYNI ANDA iki ÅŸey yapÄ±yorsun

Ant Mediaâ€™ya embed (recording / playback iÃ§in)

Metadata Serviceâ€™e publish (UI / map iÃ§in)

Åimdi detaylara girelim.

1ï¸âƒ£ â€œFFmpeg tabanlÄ± yaklaÅŸÄ±mâ€ tam olarak ne gÃ¶nderiyor?
Bu komut:
ffmpeg -i input.ts -map 0:v -c:v copy -f flv rtmp://antmedia/live/streamId
ğŸ‘‰ SADECE video gÃ¶nderir
ğŸ‘‰ Metadata yok
ğŸ‘‰ Ant Media recording metadata iÃ§ermez âŒ

Yani tek baÅŸÄ±na yeterli deÄŸil.

2ï¸âƒ£ Yol A vs Yol B ne demek?
Bunlar metadataâ€™nÄ±n Ant Mediaâ€™ya NASIL gÃ¶mÃ¼leceÄŸi ile ilgili.

ğŸ”µ Yol A â€“ ID3 (HLS odaklÄ±, en temiz yol)
Ne zaman?
HLS kullanÄ±yorsan

Playback senkronu Ã¶nemliyse

Web UI odaklÄ±ysan

NasÄ±l Ã§alÄ±ÅŸÄ±r?
Metadata video streamâ€™inden ayrÄ±

HLS segment iÃ§ine ID3 tag olarak yazÄ±lÄ±r

Ant Media recording sÄ±rasÄ±nda saklar

Kritik nokta
ğŸ‘‰ ID3 RTMPâ€™ye deÄŸil, HLS outputâ€™a eklenir
Yani:

RTMP ingest â†’ Ant Media â†’ HLS + ID3
Drone stream (canlÄ±, TS deÄŸil)
Droneâ€™dan genelde:

RTP / UDP

RTSP

SRT

gelir.

Ã–rnek (RTSP drone):

ffmpeg \
  -i rtsp://drone/stream \
  -map 0:v \
  -c:v copy \
  -f flv \
  rtmp://antmedia/live/drone-1
Bu video yoludur.

ID3 metadata nasÄ±l eklenir?
FFmpeg tek baÅŸÄ±na canlÄ± ID3 injectionâ€™da zayÄ±f.
Best practice:

Metadataâ€™yÄ± Ant Mediaâ€™ya embed etmek iÃ§in:

program_date_time

timed metadata track

Ama pratikte:
ğŸ‘‰ ID3â€™Ã¼ Ant Media tarafÄ±nda Ã¼retmek daha stabil

Yani adaptor:

metadataâ€™yÄ± Ant Mediaâ€™ya REST / hook ile verir

Ant Media HLS segmentine ID3 yazar

(Ã§ok kullanÄ±lan yÃ¶ntem)

ğŸŸ  Yol B â€“ SEI (RTMP / WebRTC, advanced)
Åimdi bunu derinleÅŸtirelim.

3ï¸âƒ£ Yol B â€“ SEI metadata (derin anlatÄ±m)
SEI nedir?
H.264 / H.265 frameâ€™lerinin iÃ§ine gÃ¶mÃ¼len metadata

Frame-accurate

Video ile asla drift etmez

Avantaj
âœ” KayÄ±t mÃ¼kemmel senkron
âœ” TS / RTMP / WebRTC fark etmez
âœ” Drone use-caseâ€™lerinde yaygÄ±n

Dezavantaj
âŒ UIâ€™da parse etmek zor
âŒ FFmpeg default destek zayÄ±f
âŒ Debug zor

SEI akÄ±ÅŸÄ± nasÄ±l olur?
Drone (RTP / RTSP)
   â†“
Adaptor
   â”œâ”€â”€ Video encode
   â”œâ”€â”€ SEI inject (JSON / binary)
   â†“
RTMP / WebRTC
   â†“
Ant Media (record + relay)
FFmpeg ile SEI injection mÃ¼mkÃ¼n mÃ¼?
SÄ±nÄ±rlÄ±.

FFmpeg SEI yazabilir

Ama custom JSON iÃ§in:

patch gerekir

ya da GStreamer daha uygun

GStreamer ile SEI (Ã¶nerilen yol)
gst-launch-1.0 \
  rtspsrc location=rtsp://drone/stream ! \
  decodebin ! \
  x264enc tune=zerolatency \
    option-string="sei-user-data=your_binary_payload" ! \
  flvmux ! \
  rtmpsink location=rtmp://antmedia/live/drone-1
Payload iÃ§ine:

{
  "lat": 41.012,
  "lon": 28.978,
  "ts": 1700001234.233
}
Ant Media SEI ile ne yapar?
Recording iÃ§ine dokunmadan yazar

Playbackâ€™te korunur

Ama:

JS player SEI okumaz

Metadata Service yine ÅŸart

4ï¸âƒ£ Drone stream iÃ§in â€œdoÄŸru kombinasyonâ€
GerÃ§ek hayatta yapÄ±lan:
AmaÃ§	YÃ¶ntem
Live video	RTMP / WebRTC
Recording sync	SEI
UI Map	Metadata Service
Replay	Metadata API
ğŸ‘‰ Yol B (SEI) + Metadata Service
ğŸ‘‰ ID3 sadece HLS playback istiyorsan eklenir

5ï¸âƒ£ Net cevaplar (tek tek)
â“ â€œHem gÃ¶rÃ¼ntÃ¼ hem metadataâ€™yÄ± mÄ± gÃ¶nderiyorum Ant Mediaâ€™ya?â€
âœ” Video her zaman
âœ” Metadata:

Recording iÃ§in â†’ SEI / ID3

UI iÃ§in â†’ AYRI servis

â“ â€œYol Aâ€™daki kod tek baÅŸÄ±na yeterli mi?â€
âŒ HayÄ±r

Sadece video taÅŸÄ±r

Metadata kaybolur

â“ â€œDrone gibi stream geliyorsa?â€
âœ” RTSP / RTP / SRT ingest
âœ” RTMP / WebRTC â†’ Ant Media
âœ” Metadata:

SEI embed

parallel publish

Son sÃ¶z (Ã¶nemli)
Ant Media medya taÅŸÄ±yÄ±cÄ±sÄ±dÄ±r,
Metadata Service gerÃ§ek zamanlÄ± zeka katmanÄ±dÄ±r.

Bunu ayÄ±rdÄ±ÄŸÄ±n an:

senkron derdin biter

UI rahatlar

kayÄ±tlar temiz olur

Bir sonraki adÄ±mda istersek:

GStreamer full pipeline

Ant Media SEI handling

Drone â†’ WebRTC low-latency setup

Hangisine devam edelim? ğŸšğŸ¥

Åunu dedin:
Ã¶nce antmedia da Ã§alÄ±ÅŸalÄ±m. bana ÅŸimdi ffmpeg ile video, id3 ve sei derin Ã§alÄ±ÅŸan Ã¶rnekleriyle verir misin
ChatGPT:
Tamam, ÅŸimdi sadece Ant Media tarafÄ±na odaklanÄ±yoruz ve istediÄŸin gibi FFmpeg ile Ã§alÄ±ÅŸan, derin ve net Ã¶rnekler vereceÄŸim.
Burada hedefimiz ÅŸu Ã¼Ã§ soruya kesin cevap vermek:

FFmpeg ile Ant Mediaâ€™ya video + ID3 nasÄ±l gider

FFmpeg ile SEI metadata gerÃ§ekten nasÄ±l gÃ¶mÃ¼lÃ¼r

Hangisi gerÃ§ekten Ã§alÄ±ÅŸÄ±r, hangisi â€œkaÄŸÄ±t Ã¼stÃ¼ndeâ€

BaÅŸtan dÃ¼rÃ¼st olayÄ±m:
FFmpeg ID3 konusunda sÄ±nÄ±rlÄ± ama yeterli,
SEI konusunda ise sÄ±nÄ±rda ama mÃ¼mkÃ¼n.
â€œProduction-grade SEIâ€ iÃ§in GStreamer daha iyi ama FFmpeg ile de gÃ¶stereceÄŸim.

1ï¸âƒ£ Ant Media ingest temeli (video only â€“ referans)
Ã–nce temiz bir baseline kuralÄ±m.

RTSP (drone) â†’ Ant Media RTMP
ffmpeg \
  -rtsp_transport tcp \
  -i rtsp://drone-ip/stream \
  -map 0:v \
  -c:v copy \
  -f flv \
  rtmp://ANTMEDIA/live/drone-1
âœ… Ant Media live
âœ… Recording
âŒ Metadata yok

Bunu referans nokta olarak aklÄ±nda tut.

2ï¸âƒ£ FFmpeg + ID3 (HLS timed metadata â€“ Ã§alÄ±ÅŸan yol)
âš ï¸ Ã–nemli gerÃ§ek:

ID3 metadata RTMP ile deÄŸil, HLS outputâ€™ta anlamlÄ±dÄ±r.

Yani:

RTMP ingest â†’ Ant Media â†’ HLS (+ ID3)
2.1 ID3 nasÄ±l Ã§alÄ±ÅŸÄ±r?
ID3 = timed metadata

HLS segment iÃ§ine gÃ¶mÃ¼lÃ¼r

Ant Media program_date_time ile bunu destekler

2.2 FFmpeg ile timed metadata track Ã¼retmek
Ã–rnek: canlÄ± stream + metadata text file
metadata.txt
0|{"lat":41.012,"lon":28.978}
1|{"lat":41.013,"lon":28.979}
2|{"lat":41.014,"lon":28.980}
FFmpeg command (video + ID3)
ffmpeg \
  -i rtsp://drone-ip/stream \
  -f data -i metadata.txt \
  -map 0:v \
  -map 1:d \
  -c:v copy \
  -c:d copy \
  -f flv \
  rtmp://ANTMEDIA/live/drone-1
ğŸ“Œ Ne olur?

Video Ant Mediaâ€™ya gider

Metadata data track olarak taÅŸÄ±nÄ±r

Ant Media HLS Ã¼retirken bunu ID3â€™e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r

2.3 Ant Media tarafÄ± (kritik ayar)
Ant Media config:

hlsMuxingEnabled=true
addDateTimeToHLS=true
SonuÃ§:

.m3u8 + .ts

Segment iÃ§inde ID3 tag

Recording korunur âœ…

2.4 GerÃ§ek hayattaki durum (dÃ¼rÃ¼st kÄ±sÄ±m)
âœ” Recording iÃ§in ID3 Ã§alÄ±ÅŸÄ±r
âœ” Playback senkron
âŒ TarayÄ±cÄ±da ID3 okumak zor
âŒ FFmpeg live JSON injection sÄ±nÄ±rlÄ±

ğŸ‘‰ Bu yÃ¼zden UI iÃ§in Metadata Service hÃ¢lÃ¢ ÅŸart

3ï¸âƒ£ FFmpeg + SEI (frame-level metadata â€“ derin konu)
Åimdi asÄ±l zor ve ilginÃ§ kÄ±sma geldik.

3.1 SEI nedir, FFmpeg ne kadar destekler?
SEI = H.264/H.265 frame iÃ§ine metadata

FFmpeg:

SEI okuyabilir

SEI kÄ±sÄ±tlÄ± yazabilir

Ama:

Custom JSON SEI injection = advanced usage

3.2 Basit SEI ekleme (user data unregistered)
FFmpegâ€™de -sei diye bir flag yok.
Ama x264opts ile user-data-unregistered SEI eklenebilir.

Ã–rnek (statik payload)
ffmpeg \
  -i rtsp://drone-ip/stream \
  -c:v libx264 \
  -x264opts "sei-user-data=lat=41.012,lon=28.978" \
  -f flv \
  rtmp://ANTMEDIA/live/drone-sei
ğŸ“Œ Bu:

Her keyframeâ€™e SEI ekler

Ant Media aynen kaydeder

Playbackâ€™te korunur

3.3 Dinamik SEI (her frame deÄŸiÅŸen metadata)
âš ï¸ FFmpeg burada zorlanÄ±r.

GerÃ§ekÃ§i yol:

External process metadata Ã¼retir

FFmpeg sendcmd / zmq ile encoder parametresi alÄ±r

Ã–rnek mimari
Metadata Generator
   â†“ (zmq)
FFmpeg (x264enc)
   â†“
SEI per frame
FFmpeg + ZMQ Ã¶rneÄŸi (advanced)
ffmpeg \
  -i rtsp://drone-ip/stream \
  -vf "zmq" \
  -c:v libx264 \
  -x264opts "sei-user-data=@sei.txt" \
  -f flv \
  rtmp://ANTMEDIA/live/drone-sei
sei.txt iÃ§eriÄŸi runtimeâ€™da gÃ¼ncellenir.

ğŸ“Œ Bu Ã§alÄ±ÅŸÄ±r ama kÄ±rÄ±lgandÄ±r.

3.4 Ant Media SEI ile ne yapar?
âœ” SEIâ€™yi bozmadan kaydeder
âœ” Live & VOD korunur
âŒ JS SDK SEI expose etmez

Yani:

Recording = mÃ¼kemmel

UI = Metadata Service

4ï¸âƒ£ Ant Media aÃ§Ä±sÄ±ndan hangisi ne zaman?
Senaryo	ID3	SEI
HLS playback	âœ…	âŒ
Frame-accurate record	âš ï¸	âœ…
Drone telemetry	âš ï¸	âœ…
FFmpeg kolaylÄ±ÄŸÄ±	âœ…	âŒ
UI consumption	âŒ	âŒ
5ï¸âƒ£ Net karar rehberi (Ant Media Ã¶zel)
EÄŸer:
HLS izletiyorum

Basit metadata yeterli

ğŸ‘‰ ID3

EÄŸer:
Drone / araÃ§ / sensÃ¶r

Frame-level doÄŸruluk

KayÄ±t Ã§ok Ã¶nemli

ğŸ‘‰ SEI + Metadata Service

Son, Ã§ok Ã¶nemli not
FFmpeg ile SEI yapÄ±lÄ±r,
ama production-grade telemetry iÃ§in
GStreamer daha doÄŸru araÃ§tÄ±r.

Bunu bilerek ilerlersen sÃ¼rpriz yaÅŸamazsÄ±n.

Bir sonraki adÄ±mda istersek:

Ant Media â†’ ID3/SEI nasÄ±l doÄŸrulanÄ±r

Recorded streamâ€™den metadata nasÄ±l extract edilir

GStreamer ile aynÄ± senaryonun temiz hali

Hangisine geÃ§iyoruz?


Daha zeki yanÄ±tlar alabilir, dosya ve gÃ¶rsel yÃ¼kleyebilir ve daha fazlasÄ±nÄ± yapabilirsin.

Oturum aÃ§

Ãœcretsiz kaydol


Dosya seÃ§ilmediDosya seÃ§ilmedi
ChatGPT hata yapabilir. Ã–nemli bilgileri kontrol edin.
